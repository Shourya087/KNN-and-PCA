{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1.  What is the fundamental idea behind ensemble techniques? How does\n",
        "bagging differ from boosting in terms of approach and objective?\n",
        "-- ensemble techniques based on idea where multiple weak models are made and run to create stronger model. bagging involves training multiple models independently and trained parallelly and their predictions are aggregated its objective is to reduce varaincel. boosting involves training multiple models sequentially its objective it to reduce bias\n",
        "\n",
        "2. Explain how the Random Forest Classifier reduces overfitting compared to\n",
        "a single decision tree. Mention the role of two key hyperparameters in this process.\n",
        "-- it reduces overfitting by bootstrap sampling where multiple subsets of training data are used with replacements and other is feature randomness where a split is made on random subset of features\n",
        "\n",
        "3. What is Stacking in ensemble learning? How does it differ from traditional\n",
        "bagging/boosting methods? Provide a simple example use case.\n",
        "-- stacking in ensemble learning is where the predictions of multiple models are used for meta model for better predicting. in stacking multiple types of algorithms can be run to prevent bais and variance\n",
        "\n",
        "4. What is the OOB Score in Random Forest, and why is it useful? How does\n",
        "it help in model evaluation without a separate validation set?\n",
        "-- OOB score is an internal validation metric used in Random Forest models to estimate performance without needing a separate validation set. it is useful as using OOB score we dont need to get a validation set other than test dataset\n",
        "\n",
        "5. Compare AdaBoost and Gradient Boosting in terms of:\n",
        "● How they handle errors from weak learners\n",
        "● Weight adjustment mechanism\n",
        "● Typical use cases\n",
        "-- adaboost handles errors by reweighting misclassified samples, while gradient boosting minimizes errors by fitting new learners to the residuals of the loss function. adaboost adjusts sample weights explicitly, whereas gradient boosting adjusts predictions via gradient descent. adaboost is often used for simpler classification tasks, while gradient boosting is favored for complex, large-scale problems like ranking, regression, and structured data modeling\n",
        "\n",
        "6. Why does CatBoost perform well on categorical features without requiring\n",
        "extensive preprocessing? Briefly explain its handling of categorical variables."
      ],
      "metadata": {
        "id": "6PDhPGIMH4Hf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vV-3LPplQvTU"
      },
      "outputs": [],
      "source": [
        "#7.KNN Classifier Assignment: Wine Dataset Analysis with Optimization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8. PCA + KNN with Variance Analysis and Visualization\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "data = load_breast_cancer()"
      ],
      "metadata": {
        "id": "pSoW41jqxxyP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.data\n",
        "y = data.target"
      ],
      "metadata": {
        "id": "GVurOtKwyCUs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
      ],
      "metadata": {
        "id": "ArdidqleyQQW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZA0byYVKyRFt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}